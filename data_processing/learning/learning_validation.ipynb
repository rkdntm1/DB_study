{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩\n",
    "\n",
    "레이블 인코딩(label encoding)과 원-핫 인코딩(one-hot encoding)을 구분된다.\n",
    "\n",
    "#### 레이블 인코딩 :  category feature를 코드형 숫자로 변환하는 것\n",
    "\n",
    "\n",
    "books=['python','java','c']등이 있을때 그 각각의 값을 숫자로 변환하는 것 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n",
      "['c' 'java' 'python']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "books=['python','java','c'] \n",
    "\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(books)\n",
    "encode_books=encoder.transform(books)\n",
    "print(encode_books)\n",
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제점 : 각 숫자로 변환을 하게 되므로 숫자의 크기로 가중치를 생각하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩(one-hot encoding)\n",
    "\n",
    "각 feature 유형에 따라 새로운 feature를 추가해 고유값에 해당하는 컬럼에 1을 표시하고   \n",
    "나머지는 0을 표시하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import  numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "books=['python','java','c'] \n",
    "encoder=LabelEncoder()\n",
    "\n",
    "encoder.fit(books)\n",
    "en_book=encoder.transform(books)\n",
    "\n",
    "en_book=en_book[:, np.newaxis]\n",
    "one_enc=OneHotEncoder()\n",
    "one_enc.fit(en_book)\n",
    "one_enbook=one_enc.transform(en_book).toarray()\n",
    "print(one_enbook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 - 교차 검증(cross validation) \n",
    "\n",
    "train_test_split(): trainSet과 testSet으로 나누는 작업 \n",
    "\n",
    "k-fold : 데이터를 비슷한 크기의 집합으로 k개 나누는 것\n",
    "\n",
    "#### k-fold  cross_validation (k-겹 교차검증)\n",
    "  그림에서처럼 k=5일때 데이터를 5개의 부분집합으로 분할 후   \n",
    "  각 분할마다 하나의 폴드를 테스트용으로 사용, 4개 폴드를 훈련으로 사용한다.   \n",
    "  이 과정을 반복하여 각 분할마다 정확도를 높인다.\n",
    "   scikit-learn: cross_val_score\n",
    "   \n",
    "   \n",
    "   =>shuffle 이용하면 fold 나누기 전 무작위로 섞음\n",
    "  \n",
    "<img src=\"./img/cross_validation.png\" width=\"400px\" height=\"450px\" align=\"left\">\n",
    "<div style=\"clear:both; padding-top:10px\">\n",
    "\n",
    "\n",
    "####  stratified k-fold cross-validation(계층별 k-겹 교차검증)\n",
    " 데이터가 편향되어 있을 경우(몰려있을 경우) => iris 경우 데이터가 편향되어 있음\n",
    "    \n",
    "    \n",
    "<img src=\"./img/str_k_fold.png\" width=\"550px\" height=\"500px\" align=\"left\">\n",
    "<div style=\"clear:both; padding-top:10px\">\n",
    "    \n",
    "클래스 A가 90%, B가 10% 일 경우 계층별 교차 검증은 각 폴드에 90%와 10%이 되도록 만듬 \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "####  shuffle split cross validation(임의 분할 교차 검증)\n",
    "    train_size 만큼의 포인트로 trainSet을 만들고, test_size 만큼으로 testSet을 만들도록 분할한다.\n",
    "    => rain set과 test set의 크기를 유연하게 조절해야 할 때 유용하다.\n",
    "    n_splits 횟수만큼 반복해서 분할 \n",
    "\n",
    "   <img src=\"./img/shuffle_cross_validation.png\" width=\"850px\" height=\"700px\" align=\"left\">\n",
    "   <div style=\"clear:both; padding-top:10px\">\n",
    "   샘플이 10개인 데이터셋을 5개의 포인트의 trainSet, 2개의 포인트의 testSet으로 4번 반복하여 나눔\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold cross_validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.9        1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "iris=load_iris()\n",
    "\n",
    "scaler=StandardScaler()\n",
    "iris_scaler=scaler.fit_transform(iris.data)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "scores=cross_val_score(logreg, iris_scaler, iris.target)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95454545 1.         0.90909091 0.95238095 0.85714286 1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores=cross_val_score(logreg, iris_scaler, iris.target, cv=7)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533085961657389\n"
     ]
    }
   ],
   "source": [
    "#교차정확도를 나타내기 위해 평균을 사용함\n",
    "\n",
    "scores=cross_val_score(logreg, iris_scaler, iris.target, cv=7)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제점\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.83333333 0.93333333 0.73333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "iris=load_iris()\n",
    "scaler=StandardScaler()\n",
    "iris_scaler=scaler.fit_transform(iris.data)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "kfold=KFold(n_splits=5)\n",
    "scores=cross_val_score(logreg, iris_scaler,iris.target ,cv=kfold)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg=LogisticRegression()\n",
    "kfold=KFold(n_splits=3)\n",
    "scores=cross_val_score(logreg, iris_scaler,iris.target ,cv=kfold)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해결책  -shufle을 이용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "kfold=KFold(n_splits=3,shuffle=True, random_state=0)\n",
    "scores=cross_val_score(logreg, iris_scaler,iris.target ,cv=kfold)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOCV( Leave-One-Out-Cross-Validation)\n",
    "\n",
    "폴드하나에 샘플 하나만 들어 있는 k-fold cross validation  \n",
    "각 반복에서 하나의 데이터 포인트를 선택해 테스트 세트로 사용   \n",
    "n개의 데이터 샘플에서 한개의 데이터 샘플을 test Set으로 하고, 나머지를 trainSet으로 검증하는 방법  \n",
    "=> 장점 : 모든 샘플에 대해 다 한번씩 test하기때문에 많은 수의 training data를  \n",
    "활용하여 model을 만들수 있다.   \n",
    "=> 단점 :  많은 수의 model을 만들고 test해야 하기 때문에 computing time이  \n",
    "굉장히 많이 걸린다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris=load_iris()\n",
    "scaler=StandardScaler()\n",
    "iris_scaler=scaler.fit_transform(iris.data)\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "\n",
    "loo=LeaveOneOut()\n",
    "score=cross_val_score(logreg, iris_scaler, iris.target, cv=loo)\n",
    "\n",
    "print(len(score))\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stratified k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "\n",
    "\n",
    "iris=load_iris()\n",
    "scaler=StandardScaler()\n",
    "iris_scaler=scaler.fit_transform(iris.data)\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "stfold= StratifiedKFold(n_splits=3)\n",
    "scores=cross_val_score(logreg, iris_scaler,iris.target ,cv=stfold)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle split cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.4 0.2 0.6 0.8 0.6 1.  0.4 0.6 1. ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "iris=load_iris()\n",
    "scaler=StandardScaler()\n",
    "iris_scaler=scaler.fit_transform(iris.data)\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "shuffle=ShuffleSplit(test_size=5, train_size=5, n_splits=10)\n",
    "scores=cross_val_score(logreg, iris_scaler,iris.target ,cv=shuffle)\n",
    "\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
